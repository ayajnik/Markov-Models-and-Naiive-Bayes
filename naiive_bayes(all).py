# -*- coding: utf-8 -*-
"""Naiive Bayes(all)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12pPgzDrDGS7lmMfymlSaPNv1O5eX5isP
"""

import numpy as np
import pandas as pd

jo = open("wheelership.txt", encoding='utf-8').read()

print(jo)

##split the data into words
corpus = jo.split()

print(corpus)

def make_pairs(corpus):
    for i in range(len(corpus) - 1):
        yield(corpus[i], corpus[i+1])

pairs = make_pairs(corpus)

##appending the dictionary

word_dict = {}

for word_1, word_2 in pairs:
    if word_1 in word_dict.keys():
        word_dict[word_1].append(word_2)
    else:
        word_dict[word_1] = [word_2]

##building the markov model

first_word = np.random.choice(corpus)

while first_word.islower():
    first_word = np.random.choice(corpus)

chain = [first_word]

n_words = 20

for i in range(n_words):
    chain.append(np.random.choice(word_dict[chain[-1]]))

##prediction

xy = (' '.join(chain))
print(xy)

!pip install seaborn

##detection
##ML Packages For Vectorization of Text For Feature Extraction
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Visualization Packages
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("SalesData1.csv", error_bad_lines = False)

a = df['weight'].mean

a

df['weight'].fillna(a)

types = {'simple': 1,'bundle': 2, 'other':3}
df.product_type = [types[item] for item in df.product_type]

df.head()

df.tail()

df_x = df['name']
df_y = df['product_type']

cv = CountVectorizer()
ex = cv.fit_transform(["Replacement for Honda Civic"])

ex.toarray()

cv.get_feature_names()

# Extract Feature With CountVectorizer
corpus = df_x
cv = CountVectorizer()
X = cv.fit_transform(corpus) # Fit the Data

X.toarray()

# get the feature names
cv.get_feature_names()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, df_y, test_size=0.33, random_state=42)

X_train

# Naive Bayes Classifier
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB()
clf.fit(X_train,y_train)
clf.score(X_test,y_test)

# Accuracy of our Model
print("Accuracy of Model",clf.score(X_test,y_test)*100,"%")

## Predicting with our model
clf.predict(X_test)

# Sample Prediciton
comment = ["Set of 4 New 16 x 7 Wheel for Honda Accord LX 2016 2017 Rim 64078 with Center Caps"]
vect = cv.transform(comment).toarray()

clf.predict(vect)

class_dict = {'simple':0,'bundle':1}

class_dict.values()

if clf.predict(vect) == 1:
    print("bundle")
else:
    print("simple")

# Sample Prediciton 2
comment1 = ["Great song Friend"]
vect = cv.transform(comment1).toarray()
clf.predict(vect)

!pip install pickle

import pickle

naivebayesML = open("twllc.pkl","wb")

pickle.dump(clf,naivebayesML)

naivebayesML.close()

ytb_model = open("twllc.pkl","rb")

new_model = pickle.load(ytb_model)

new_model

# Sample Prediciton 3
comment2 = ['E-Series E-150 E-250 SD E-350 F-Series Excursion 1999-2015 Driver Left Side New 18 x 8.5" Front Wheel for Pontiac G6 2005']
vect = cv.transform(comment2).toarray()
new_model.predict(vect)

if new_model.predict(vect) == 1:
    print("Bundle")
else:
    print("Simple")

